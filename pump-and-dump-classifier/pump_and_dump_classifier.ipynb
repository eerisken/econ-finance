{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import copy\n",
        "\n",
        "# --- Framework-agnostic Data Generation Code ---\n",
        "class StockOracle:\n",
        "    \"\"\"\n",
        "    A class to simulate a stock's price using various stochastic processes.\n",
        "    This version is simplified for generating clean datasets for the ML model.\n",
        "    \"\"\"\n",
        "    def __init__(self, periods=252, x0=100, kappa=0.5, theta=100, sigma=0.5,\n",
        "                 pump_start_percent=0.4, pump_end_percent=0.6, dump_end_percent=0.7,\n",
        "                 post_dump_drift_strength=0.1, simulation_type=\"pump_and_dump\", trend_drift=0.5):\n",
        "        self.periods = periods\n",
        "        self.x0 = x0\n",
        "        self.kappa = kappa\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.pump_start_percent = pump_start_percent\n",
        "        self.pump_end_percent = pump_end_percent\n",
        "        self.dump_end_percent = dump_end_percent\n",
        "        self.post_dump_drift_strength = post_dump_drift_strength\n",
        "        self.simulation_type = simulation_type\n",
        "        self.trend_drift = trend_drift\n",
        "\n",
        "        if self.simulation_type == \"pump_and_dump\":\n",
        "            self.price_history = self._simulate_pump_dump_data()\n",
        "        elif self.simulation_type == \"mean_reverting\":\n",
        "            self.price_history = self._simulate_mean_reverting_data()\n",
        "        elif self.simulation_type == \"trend\":\n",
        "            self.price_history = self._simulate_trend_data()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid simulation_type provided.\")\n",
        "\n",
        "    def _simulate_pump_dump_data(self):\n",
        "        s = [self.x0]\n",
        "        dt = 1.0 / self.periods\n",
        "        pump_start_idx = int(self.periods * self.pump_start_percent)\n",
        "        pump_end_idx = int(self.periods * self.pump_end_percent)\n",
        "        dump_end_idx = int(self.periods * self.dump_end_percent)\n",
        "\n",
        "        for t in range(1, self.periods):\n",
        "            s_t_minus_1 = s[t - 1]\n",
        "            drift = self.kappa * (self.theta - s_t_minus_1) * dt\n",
        "            volatility = s_t_minus_1 * self.sigma * math.sqrt(dt) * random.gauss(0, 1)\n",
        "            additional_drift = 0\n",
        "\n",
        "            if pump_start_idx <= t < pump_end_idx:\n",
        "                additional_drift = 2.0 * dt * self.x0\n",
        "            elif pump_end_idx <= t < dump_end_idx:\n",
        "                additional_drift = -5.0 * dt * self.x0\n",
        "            elif t >= dump_end_idx:\n",
        "                additional_drift = -self.post_dump_drift_strength * (s_t_minus_1 - self.x0) * dt\n",
        "\n",
        "            s_t = (s_t_minus_1 + drift + volatility + additional_drift)\n",
        "            s.append(max(0, s_t))\n",
        "        return np.array(s)\n",
        "\n",
        "    def _simulate_mean_reverting_data(self):\n",
        "        s = [self.x0]\n",
        "        dt = 1.0 / self.periods\n",
        "        for t in range(1, self.periods):\n",
        "            s_t_minus_1 = s[t - 1]\n",
        "            drift = self.kappa * (self.theta - s_t_minus_1) * dt\n",
        "            volatility = s_t_minus_1 * self.sigma * math.sqrt(dt) * random.gauss(0, 1)\n",
        "            s_t = (s_t_minus_1 + drift + volatility)\n",
        "            s.append(max(0, s_t))\n",
        "        return np.array(s)\n",
        "\n",
        "    def _simulate_trend_data(self):\n",
        "        s = [self.x0]\n",
        "        dt = 1.0 / self.periods\n",
        "        for t in range(1, self.periods):\n",
        "            s_t_minus_1 = s[t - 1]\n",
        "            drift = self.trend_drift * dt * self.x0\n",
        "            volatility = s_t_minus_1 * self.sigma * math.sqrt(dt) * random.gauss(0, 1)\n",
        "            s_t = (s_t_minus_1 + drift + volatility)\n",
        "            s.append(max(0, s_t))\n",
        "        return np.array(s)\n",
        "\n",
        "def generate_dataset(num_samples, periods):\n",
        "    \"\"\"\n",
        "    Generates a synthetic dataset of stock price time series.\n",
        "    Returns:\n",
        "        X (np.array): shape (num_samples, periods)\n",
        "        y (np.array): shape (num_samples, 1)\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Number of samples for each class\n",
        "    num_pump_dump = int(num_samples * 0.5)\n",
        "    num_normal = num_samples - num_pump_dump\n",
        "    num_mean_reverting = num_normal // 2\n",
        "    num_trend = num_normal - num_mean_reverting\n",
        "\n",
        "    # Generate pump-and-dump data\n",
        "    for _ in range(num_pump_dump):\n",
        "        oracle = StockOracle(periods=periods, x0=100 + random.uniform(-20, 20),\n",
        "                             sigma=random.uniform(0.1, 0.7),\n",
        "                             pump_start_percent=random.uniform(0.1, 0.4),\n",
        "                             pump_end_percent=random.uniform(0.5, 0.7),\n",
        "                             dump_end_percent=random.uniform(0.7, 0.9))\n",
        "        X.append(oracle._simulate_pump_dump_data())\n",
        "        y.append(1)\n",
        "\n",
        "    # Generate normal mean-reverting data\n",
        "    for _ in range(num_mean_reverting):\n",
        "        oracle = StockOracle(periods=periods, x0=100 + random.uniform(-20, 20),\n",
        "                             sigma=random.uniform(0.1, 0.5),\n",
        "                             theta=100 + random.uniform(-20, 20))\n",
        "        X.append(oracle._simulate_mean_reverting_data())\n",
        "        y.append(0)\n",
        "\n",
        "    # Generate normal trending data\n",
        "    for _ in range(num_trend):\n",
        "        oracle = StockOracle(periods=periods, x0=100 + random.uniform(-20, 20),\n",
        "                             sigma=random.uniform(0.1, 0.5),\n",
        "                             trend_drift=random.uniform(-0.005, 0.005))\n",
        "        X.append(oracle._simulate_trend_data())\n",
        "        y.append(0)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y).reshape(-1, 1)\n",
        "\n",
        "    # Shuffle the data\n",
        "    indices = np.arange(num_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    return X[indices], y[indices]\n",
        "\n",
        "def normalize_data(data):\n",
        "    \"\"\"\n",
        "    Normalizes a dataset of multiple time series using Min-Max Scaling on each series.\n",
        "    \"\"\"\n",
        "    normalized_data = np.zeros_like(data, dtype=np.float32)\n",
        "    for i in range(data.shape[0]):\n",
        "        series = data[i, :]\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        # Reshape for the scaler: (n_samples, n_features)\n",
        "        normalized_series = scaler.fit_transform(series.reshape(-1, 1)).flatten()\n",
        "        normalized_data[i, :] = normalized_series\n",
        "    return normalized_data\n",
        "\n",
        "def generate_windowed_dataset(X, y, window_size, stride):\n",
        "    \"\"\"\n",
        "    Generates a windowed dataset from the full time series.\n",
        "    Args:\n",
        "        X (np.array): Full time series data, shape (num_samples, periods)\n",
        "        y (np.array): Labels for the full time series, shape (num_samples, 1)\n",
        "        window_size (int): The number of time steps in each window.\n",
        "        stride (int): The number of steps the window moves forward each time.\n",
        "    Returns:\n",
        "        X_windowed (np.array): The windowed data, shape (num_windows, window_size, 1)\n",
        "        y_windowed (np.array): Labels for each window, shape (num_windows, 1)\n",
        "    \"\"\"\n",
        "    X_windowed = []\n",
        "    y_windowed = []\n",
        "\n",
        "    # Ensure y is a 2D array for consistent indexing\n",
        "    y = y.reshape(-1, 1)\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "        series = X[i, :]\n",
        "        label = y[i, 0]\n",
        "\n",
        "        # Determine the pump-and-dump period for labeling\n",
        "        # This is a key step to correctly label windows\n",
        "        if label == 1:\n",
        "            pump_start_idx = np.where(series > 1.2 * series[0])[0][0] if np.any(series > 1.2 * series[0]) else len(series)\n",
        "            dump_end_idx = np.argmax(series) + np.where(series[np.argmax(series):] < 0.7 * series[np.argmax(series)])[0][0] if np.any(series[np.argmax(series):] < 0.7 * series[np.argmax(series)]) else len(series)\n",
        "        else:\n",
        "            pump_start_idx, dump_end_idx = -1, -1 # No pump-and-dump for normal series\n",
        "\n",
        "        # Create windows for this series\n",
        "        for j in range(0, series.shape[0] - window_size + 1, stride):\n",
        "            window = series[j:j + window_size]\n",
        "            X_windowed.append(window)\n",
        "\n",
        "            # Assign label based on whether the window contains the pump-and-dump event\n",
        "            window_end_idx = j + window_size\n",
        "            if label == 1 and (\n",
        "                (j <= pump_start_idx < window_end_idx) or\n",
        "                (j <= dump_end_idx < window_end_idx) or\n",
        "                (pump_start_idx >= j and dump_end_idx <= window_end_idx)\n",
        "            ):\n",
        "                y_windowed.append(1)\n",
        "            else:\n",
        "                y_windowed.append(0)\n",
        "\n",
        "    X_windowed = np.array(X_windowed)\n",
        "    y_windowed = np.array(y_windowed).reshape(-1, 1)\n",
        "\n",
        "    return X_windowed, y_windowed\n",
        "\n",
        "# --- PyTorch Specific Code ---\n",
        "\n",
        "class TimeseriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom PyTorch Dataset for time series data.\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = torch.tensor(sequences, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sequences[idx], self.labels[idx]\n",
        "\n",
        "# --- Model Definition ---\n",
        "class PumpDumpClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A PyTorch-based LSTM model to classify time-series data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout_prob=0.2):\n",
        "        super(PumpDumpClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_hidden_state = lstm_out[:, -1, :]\n",
        "        out = self.fc(last_hidden_state)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "id": "pegm0sXGetLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Hyperparameters\n",
        "    NUM_SAMPLES = 30_000\n",
        "    PERIODS = 252 # Number of trading days in a year\n",
        "    WINDOW_SIZE = 120 # Number of days in each window\n",
        "    STRIDE = 15 # The step size for the sliding window\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    INPUT_SIZE = 1\n",
        "    HIDDEN_SIZE = 64\n",
        "    NUM_LAYERS = 2\n",
        "    DROPOUT_RATE = 0.2\n",
        "\n",
        "    # Early stopping parameters\n",
        "    PATIENCE = 5\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    print(\"Generating synthetic data...\")\n",
        "    X_full, y_full = generate_dataset(num_samples=NUM_SAMPLES, periods=PERIODS)\n",
        "    X_full = normalize_data(X_full)\n",
        "    print(\"Synthetic data normalized.\")\n",
        "\n",
        "    print(\"Creating windowed dataset...\")\n",
        "    X_windowed, y_windowed = generate_windowed_dataset(X_full, y_full, WINDOW_SIZE, STRIDE)\n",
        "    print(f\"Original series: {NUM_SAMPLES}, Windowed samples: {X_windowed.shape[0]}\")\n",
        "    print(f\"Pump-and-Dump windows: {np.sum(y_windowed)} | Normal windows: {len(y_windowed) - np.sum(y_windowed)}\")\n",
        "\n",
        "    # Split the windowed data into training, validation, and test sets\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X_windowed, y_windowed, test_size=0.2, random_state=42, stratify=y_windowed\n",
        "    )\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=0.1, random_state=42, stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Create PyTorch datasets and dataloaders\n",
        "    train_dataset = TimeseriesDataset(X_train.reshape(-1, WINDOW_SIZE, INPUT_SIZE), y_train)\n",
        "    val_dataset = TimeseriesDataset(X_val.reshape(-1, WINDOW_SIZE, INPUT_SIZE), y_val)\n",
        "    test_dataset = TimeseriesDataset(X_test.reshape(-1, WINDOW_SIZE, INPUT_SIZE), y_test)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(\"\\nTraining PyTorch LSTM model with early stopping...\")\n",
        "    model = PumpDumpClassifier(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT_RATE).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for i, (sequences, labels) in enumerate(train_loader):\n",
        "            sequences = sequences.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels) # Fixed here\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            for sequences, labels in val_loader:\n",
        "                sequences = sequences.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(sequences)\n",
        "                val_loss += criterion(outputs, labels).item() # Fixed here\n",
        "            val_loss /= len(val_loader)\n",
        "            print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(f\"Early stopping at epoch {epoch+1}. Restoring best model state.\")\n",
        "                model.load_state_dict(best_model_state)\n",
        "                break\n",
        "\n",
        "    print(\"\\nEvaluating model performance...\")\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in test_loader:\n",
        "            sequences = sequences.to(device)\n",
        "            outputs = model(sequences)\n",
        "            predicted = outputs.round()\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Pump-and-Dump\"]))\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'best_model_windowed.pth')\n",
        "    print(\"\\nModel saved to best_model_windowed.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycSh7-2He5Ly",
        "outputId": "3092e5ee-b2ad-4764-b0d3-289a354a5809"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Generating synthetic data...\n",
            "Synthetic data normalized.\n",
            "Creating windowed dataset...\n",
            "Original series: 30000, Windowed samples: 270000\n",
            "Pump-and-Dump windows: 114236 | Normal windows: 155764\n",
            "\n",
            "Training PyTorch LSTM model with early stopping...\n",
            "Epoch [1/50], Loss: 0.2993, Validation Loss: 0.4599\n",
            "Epoch [2/50], Loss: 0.2856, Validation Loss: 0.3359\n",
            "Epoch [3/50], Loss: 0.3087, Validation Loss: 0.2925\n",
            "Epoch [4/50], Loss: 0.2568, Validation Loss: 0.2823\n",
            "Epoch [5/50], Loss: 0.2061, Validation Loss: 0.2754\n",
            "Epoch [6/50], Loss: 0.2805, Validation Loss: 0.2677\n",
            "Epoch [7/50], Loss: 0.2170, Validation Loss: 0.2600\n",
            "Epoch [8/50], Loss: 0.1172, Validation Loss: 0.2570\n",
            "Epoch [9/50], Loss: 0.3003, Validation Loss: 0.2543\n",
            "Epoch [10/50], Loss: 0.1714, Validation Loss: 0.2530\n",
            "Epoch [11/50], Loss: 0.2371, Validation Loss: 0.2548\n",
            "Epoch [12/50], Loss: 0.2475, Validation Loss: 0.2529\n",
            "Epoch [13/50], Loss: 0.3162, Validation Loss: 0.2551\n",
            "Epoch [14/50], Loss: 0.1946, Validation Loss: 0.2512\n",
            "Epoch [15/50], Loss: 0.2573, Validation Loss: 0.2517\n",
            "Epoch [16/50], Loss: 0.1483, Validation Loss: 0.2543\n",
            "Epoch [17/50], Loss: 0.1866, Validation Loss: 0.2484\n",
            "Epoch [18/50], Loss: 0.2325, Validation Loss: 0.2496\n",
            "Epoch [19/50], Loss: 0.2276, Validation Loss: 0.2492\n",
            "Epoch [20/50], Loss: 0.1492, Validation Loss: 0.2491\n",
            "Epoch [21/50], Loss: 0.2084, Validation Loss: 0.2569\n",
            "Epoch [22/50], Loss: 0.3346, Validation Loss: 0.2465\n",
            "Epoch [23/50], Loss: 0.4481, Validation Loss: 0.2455\n",
            "Epoch [24/50], Loss: 0.2944, Validation Loss: 0.2438\n",
            "Epoch [25/50], Loss: 0.0618, Validation Loss: 0.2484\n",
            "Epoch [26/50], Loss: 0.2663, Validation Loss: 0.2479\n",
            "Epoch [27/50], Loss: 0.1660, Validation Loss: 0.2432\n",
            "Epoch [28/50], Loss: 0.2947, Validation Loss: 0.2429\n",
            "Epoch [29/50], Loss: 0.2291, Validation Loss: 0.2474\n",
            "Epoch [30/50], Loss: 0.2428, Validation Loss: 0.2424\n",
            "Epoch [31/50], Loss: 0.1797, Validation Loss: 0.2427\n",
            "Epoch [32/50], Loss: 0.2006, Validation Loss: 0.2443\n",
            "Epoch [33/50], Loss: 0.0902, Validation Loss: 0.2467\n",
            "Epoch [34/50], Loss: 0.2360, Validation Loss: 0.2485\n",
            "Epoch [35/50], Loss: 0.3004, Validation Loss: 0.2422\n",
            "Epoch [36/50], Loss: 0.1375, Validation Loss: 0.2469\n",
            "Epoch [37/50], Loss: 0.2603, Validation Loss: 0.2420\n",
            "Epoch [38/50], Loss: 0.1886, Validation Loss: 0.2420\n",
            "Epoch [39/50], Loss: 0.1141, Validation Loss: 0.2422\n",
            "Epoch [40/50], Loss: 0.1628, Validation Loss: 0.2427\n",
            "Epoch [41/50], Loss: 0.2002, Validation Loss: 0.2439\n",
            "Epoch [42/50], Loss: 0.1889, Validation Loss: 0.2431\n",
            "Epoch [43/50], Loss: 0.0799, Validation Loss: 0.2419\n",
            "Epoch [44/50], Loss: 0.2069, Validation Loss: 0.2413\n",
            "Epoch [45/50], Loss: 0.1531, Validation Loss: 0.2460\n",
            "Epoch [46/50], Loss: 0.2345, Validation Loss: 0.2439\n",
            "Epoch [47/50], Loss: 0.1541, Validation Loss: 0.2490\n",
            "Epoch [48/50], Loss: 0.3444, Validation Loss: 0.2393\n",
            "Epoch [49/50], Loss: 0.3455, Validation Loss: 0.2432\n",
            "Epoch [50/50], Loss: 0.3827, Validation Loss: 0.2405\n",
            "\n",
            "Evaluating model performance...\n",
            "Accuracy: 0.8903\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Normal       0.90      0.91      0.91     31153\n",
            "Pump-and-Dump       0.88      0.86      0.87     22847\n",
            "\n",
            "     accuracy                           0.89     54000\n",
            "    macro avg       0.89      0.89      0.89     54000\n",
            " weighted avg       0.89      0.89      0.89     54000\n",
            "\n",
            "\n",
            "Model saved to best_model_windowed.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from datetime import date\n",
        "\n",
        "# Suppress DeprecationWarnings from jupyter_client\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=DeprecationWarning,\n",
        "    module=\"jupyter_client\",\n",
        "    message=\"datetime.datetime.utcnow() is deprecated\"\n",
        ")\n",
        "\n",
        "def get_bist_all_tickers(filepath):\n",
        "    \"\"\"\n",
        "    Fetches the list of tickers for all Borsa Istanbul stocks from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): The path to the CSV file containing the ticker list.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of ticker symbols.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tickers_df = pd.read_csv(filepath)\n",
        "        if \"ticker\" not in tickers_df.columns:\n",
        "            print(f\"Error: The CSV file '{filepath}' must contain a 'ticker' column.\")\n",
        "            return []\n",
        "\n",
        "        tickers_df[\"ticker\"] = tickers_df[\"ticker\"] + \".IS\"\n",
        "        tickers = tickers_df[\"ticker\"].dropna().tolist()\n",
        "        return tickers\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filepath}' was not found.\")\n",
        "        return []\n",
        "\n",
        "def download_bist_data(start_date, end_date, ticker_list):\n",
        "    \"\"\"\n",
        "    Downloads adjusted close prices for a list of Borsa Istanbul stocks.\n",
        "\n",
        "    Args:\n",
        "        start_date (str): The start date for the data (YYYY-MM-DD).\n",
        "        end_date (str): The end date for the data (YYYY-MM-DD).\n",
        "        ticker_list (list): A list of ticker symbols to download.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame with adjusted close prices for each stock.\n",
        "    \"\"\"\n",
        "    if not ticker_list:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Downloading data for {len(ticker_list)} Borsa Istanbul stocks...\")\n",
        "\n",
        "    # Download data for all tickers in a single request.\n",
        "    data = yf.download(\n",
        "        tickers=ticker_list,\n",
        "        start=start_date,\n",
        "        end=end_date,\n",
        "        group_by='ticker',\n",
        "        auto_adjust=True,  # Automatically adjusts prices for splits and dividends\n",
        "        progress=True     # Show progress bar\n",
        "    )\n",
        "\n",
        "    # Extract only the 'Close' prices from the MultiIndex DataFrame.\n",
        "    close_prices = data.loc[:, (slice(None), 'Close')]\n",
        "\n",
        "    # Clean up column names by dropping the 'Close' level.\n",
        "    close_prices.columns = close_prices.columns.droplevel(1)\n",
        "\n",
        "    # Remove any stocks that have missing data due to delisting or other issues.\n",
        "    close_prices.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "    return close_prices\n",
        "\n",
        "# Define the date range for 2024\n",
        "start_date = \"2024-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "# Specify the path to your tickers CSV file\n",
        "tickers_csv_file = \"bist.csv\"\n",
        "\n",
        "# Get the list of tickers from the CSV file\n",
        "bist_tickers = get_bist_all_tickers(tickers_csv_file)\n",
        "\n",
        "if bist_tickers:\n",
        "    # Download the data\n",
        "    bist_prices = download_bist_data(start_date, end_date, bist_tickers)\n",
        "\n",
        "    if not bist_prices.empty:\n",
        "        # Save the data to a CSV file.\n",
        "        output_filename = \"bist_2024_prices.csv\"\n",
        "        bist_prices.to_csv(output_filename)\n",
        "        print(f\"\\nSuccessfully downloaded data for {bist_prices.shape[1]} stocks.\")\n",
        "        print(f\"Data saved to '{output_filename}'\")\n",
        "        print(\"\\nFirst 5 rows of the downloaded data:\")\n",
        "        print(bist_prices.head())\n",
        "        print(\"\\nLast 5 rows of the downloaded data:\")\n",
        "        print(bist_prices.tail())\n",
        "    else:\n",
        "        print(\"Failed to download any stock data. Please check ticker list and dates.\")\n",
        "else:\n",
        "    print(\"No tickers found. Please create a CSV file named 'bist_tickers.csv' with a 'ticker' column.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpwMRrF4q9Cl",
        "outputId": "8f1ebca7-1b5b-4c47-98a4-5659e2730f88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                       0%                       ]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for 585 Borsa Istanbul stocks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  585 of 585 completed\n",
            "ERROR:yfinance:\n",
            "16 Failed downloads:\n",
            "ERROR:yfinance:['VSNMD.IS', 'BIGEN.IS', 'BALSU.IS', 'GLRMK.IS', 'AKFIS.IS', 'RUZYE.IS', 'ARMGD.IS', 'KLYPV.IS', 'BESLR.IS', 'MOPAS.IS', 'A1YEN.IS', 'BULGS.IS', 'EGEGY.IS', 'DSTKF.IS', 'ENDAE.IS', 'SERNT.IS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1704056400, endDate = 1735592400\")')\n",
            "/tmp/ipython-input-1251156322.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  close_prices.dropna(axis=1, how='all', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully downloaded data for 569 stocks.\n",
            "Data saved to 'bist_2024_prices.csv'\n",
            "\n",
            "First 5 rows of the downloaded data:\n",
            "Ticker         ISBTR.IS   SARKY.IS   GOZDE.IS   ALFAS.IS  PEKGY.IS  \\\n",
            "Date                                                                 \n",
            "2024-01-02  574999.0625  13.908443  21.260000  87.048950  8.488133   \n",
            "2024-01-03  559999.0625  13.170874  20.180000  86.210518  8.300579   \n",
            "2024-01-04  559999.0625  13.036770  20.320000  83.991142  8.145178   \n",
            "2024-01-05  559999.0625  13.333714  20.860001  82.264954  7.984418   \n",
            "2024-01-08  579999.0625  13.314556  20.600000  84.089775  8.225558   \n",
            "\n",
            "Ticker        AZTEK.IS    SOKM.IS   ASGYO.IS   AVPGY.IS  KLSYN.IS  ...  \\\n",
            "Date                                                               ...   \n",
            "2024-01-02  106.738441  51.494812  14.475744  36.038033  5.015153  ...   \n",
            "2024-01-03  110.516792  51.351372  13.481152  34.334885  4.789863  ...   \n",
            "2024-01-04  109.572205  51.351372  13.924288  34.642899  4.956382  ...   \n",
            "2024-01-05  114.106239  51.446995  14.022761  35.838734  4.995563  ...   \n",
            "2024-01-08  116.278786  52.355450  14.022761  38.139797  5.093515  ...   \n",
            "\n",
            "Ticker      ETILR.IS  MZHLD.IS   PENTA.IS  EUKYO.IS     BRYAT.IS  YGYO.IS  \\\n",
            "Date                                                                        \n",
            "2024-01-02  4.270000      7.94  18.639999     14.83  2374.864746     3.44   \n",
            "2024-01-03  4.106666      7.51  18.500000     13.90  2225.778809     3.36   \n",
            "2024-01-04  4.156666      7.63  19.309999     13.60  2258.271729     3.29   \n",
            "2024-01-05  4.213333      7.75  19.629999     13.78  2262.094482     3.32   \n",
            "2024-01-08  4.263333      8.00  19.389999     13.63  2247.759277     3.27   \n",
            "\n",
            "Ticker      LKMNH.IS   GIPTA.IS   ISGSY.IS   CELHA.IS  \n",
            "Date                                                   \n",
            "2024-01-02  9.447506  28.424206  23.459999  21.864332  \n",
            "2024-01-03  8.507617  27.343811  23.000000  22.415277  \n",
            "2024-01-04  8.118698  27.304522  24.260000  22.925411  \n",
            "2024-01-05  8.047395  27.933117  25.000000  22.935614  \n",
            "2024-01-08  8.070083  28.149197  25.180000  23.700813  \n",
            "\n",
            "[5 rows x 569 columns]\n",
            "\n",
            "Last 5 rows of the downloaded data:\n",
            "Ticker          ISBTR.IS   SARKY.IS   GOZDE.IS   ALFAS.IS  PEKGY.IS  \\\n",
            "Date                                                                  \n",
            "2024-12-24  509999.78125  10.554091  25.420000  61.900002      1.56   \n",
            "2024-12-25  510002.28125  10.877117  26.500000  64.199997      1.55   \n",
            "2024-12-26  509997.28125  11.041565  26.280001  66.800003      1.53   \n",
            "2024-12-27  494999.78125  11.012199  26.200001  67.199997      1.54   \n",
            "2024-12-30  495002.28125  10.894736  25.280001  68.050003      1.51   \n",
            "\n",
            "Ticker       AZTEK.IS    SOKM.IS  ASGYO.IS   AVPGY.IS  KLSYN.IS  ...  \\\n",
            "Date                                                             ...   \n",
            "2024-12-24  45.639656  39.380001     12.65  52.822502  5.475529  ...   \n",
            "2024-12-25  45.252876  40.060001     12.74  54.295078  5.446143  ...   \n",
            "2024-12-26  45.291557  40.560001     12.72  52.727505  5.426553  ...   \n",
            "2024-12-27  45.156185  41.560001     12.53  51.777454  5.485324  ...   \n",
            "2024-12-30  45.136845  41.060001     12.28  52.204975  5.583276  ...   \n",
            "\n",
            "Ticker      ETILR.IS  MZHLD.IS  PENTA.IS   EUKYO.IS     BRYAT.IS  YGYO.IS  \\\n",
            "Date                                                                        \n",
            "2024-12-24      7.66      6.54     14.95  15.500000  2087.902344     9.34   \n",
            "2024-12-25      7.49      6.50     15.06  16.059999  2053.991943     9.39   \n",
            "2024-12-26      7.30      6.60     15.08  15.450000  2018.144043     9.59   \n",
            "2024-12-27      7.22      6.66     15.23  15.100000  2014.268555     9.69   \n",
            "2024-12-30      6.99      6.61     15.65  15.360000  1991.015869     9.66   \n",
            "\n",
            "Ticker       LKMNH.IS   GIPTA.IS   ISGSY.IS   CELHA.IS  \n",
            "Date                                                    \n",
            "2024-12-24  15.959717  39.568321  34.500000  21.980000  \n",
            "2024-12-25  16.137377  39.627705  35.520000  21.980000  \n",
            "2024-12-26  16.818403  41.092464  37.759998  22.000000  \n",
            "2024-12-27  17.341511  41.646698  37.639999  21.879999  \n",
            "2024-12-30  17.923838  42.755165  37.820000  21.340000  \n",
            "\n",
            "[5 rows x 569 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bist_prices.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggp7CifnvO6f",
        "outputId": "38ef1553-84d2-4369-e011-b1acae006936"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(249, 569)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "# Suppress DeprecationWarnings from jupyter_client\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=DeprecationWarning,\n",
        "    module=\"jupyter_client\",\n",
        "    message=\"datetime.datetime.utcnow() is deprecated\"\n",
        ")\n",
        "\n",
        "# --- Data Preprocessing and Padding ---\n",
        "def pad_series_to_length(series, target_length):\n",
        "    \"\"\"\n",
        "    Pads a pandas Series to a target length by repeating the last value.\n",
        "    \"\"\"\n",
        "    current_length = len(series)\n",
        "    if current_length >= target_length:\n",
        "        return series\n",
        "\n",
        "    num_to_pad = target_length - current_length\n",
        "    last_value = series.iloc[-1]\n",
        "    padded_values = [last_value] * num_to_pad\n",
        "\n",
        "    padded_series = pd.concat([series, pd.Series(padded_values, index=range(current_length, target_length))])\n",
        "    return padded_series.reset_index(drop=True)\n",
        "\n",
        "def normalize_series(series):\n",
        "    \"\"\"\n",
        "    Normalizes a single pandas Series using Min-Max Scaling.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_series = scaler.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
        "    return normalized_series\n",
        "\n",
        "def create_sliding_windows(series, window_size, stride):\n",
        "    \"\"\"\n",
        "    Creates overlapping or non-overlapping windows from a time series.\n",
        "    Returns:\n",
        "        np.array: A 2D array of windows.\n",
        "    \"\"\"\n",
        "    windows = []\n",
        "    for i in range(0, len(series) - window_size + 1, stride):\n",
        "        windows.append(series[i : i + window_size])\n",
        "    return np.array(windows)\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Define constants\n",
        "    BIST_DATA_FILE = \"bist_2024_prices.csv\"\n",
        "    MODEL_FILE = \"best_model_windowed.pth\"\n",
        "    TARGET_LENGTH = 252\n",
        "\n",
        "    # Windowing parameters from your training script\n",
        "    WINDOW_SIZE = 120\n",
        "    STRIDE = 15\n",
        "\n",
        "    INPUT_SIZE = 1\n",
        "    HIDDEN_SIZE = 64\n",
        "    NUM_LAYERS = 2\n",
        "    DROPOUT_RATE = 0.2\n",
        "\n",
        "    try:\n",
        "        # Load the downloaded BIST stock data\n",
        "        if not os.path.exists(BIST_DATA_FILE):\n",
        "            raise FileNotFoundError(f\"Error: The file '{BIST_DATA_FILE}' was not found. Please run the data download script first.\")\n",
        "        bist_prices = pd.read_csv(BIST_DATA_FILE, index_col=0, parse_dates=True)\n",
        "        print(f\"Successfully loaded data from '{BIST_DATA_FILE}'.\")\n",
        "\n",
        "        # Load the trained PyTorch model\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = PumpDumpClassifier(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout_prob=DROPOUT_RATE).to(device)\n",
        "        model.load_state_dict(torch.load(MODEL_FILE, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"Successfully loaded trained model from '{MODEL_FILE}'.\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "        exit()\n",
        "\n",
        "    # Create a DataFrame to store the results\n",
        "    results = pd.DataFrame(columns=['Ticker', 'Total Windows', 'Pump-and-Dump Flags'])\n",
        "\n",
        "    # Loop through each stock to test the model\n",
        "    print(\"\\nAnalyzing BIST stocks...\")\n",
        "    for ticker in bist_prices.columns:\n",
        "        stock_series = bist_prices[ticker].dropna()\n",
        "\n",
        "        # Check if the series is long enough to create a single window\n",
        "        if len(stock_series) < WINDOW_SIZE:\n",
        "            print(f\"  - Skipping {ticker}: Not enough data for a single window ({len(stock_series)} < {WINDOW_SIZE}).\")\n",
        "            continue\n",
        "\n",
        "        # Create sliding windows\n",
        "        windows = create_sliding_windows(stock_series, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "        # Normalize each window individually\n",
        "        normalized_windows = np.array([normalize_series(pd.Series(w)) for w in windows])\n",
        "\n",
        "        # Reshape for the LSTM model: (num_windows, sequence_length, input_size)\n",
        "        x_tensor = torch.tensor(normalized_windows, dtype=torch.float32).unsqueeze(-1).to(device)\n",
        "\n",
        "        # Make prediction on all windows for this stock\n",
        "        with torch.no_grad():\n",
        "            prediction_probs = model(x_tensor).cpu().numpy().flatten()\n",
        "\n",
        "        # Count the number of windows flagged as \"Pump-and-Dump\" (prob > 0.5)\n",
        "        pump_dump_count = np.sum(prediction_probs > 0.5)\n",
        "        total_windows = len(windows)\n",
        "\n",
        "        # Store the results\n",
        "        new_row = pd.DataFrame([{\n",
        "            'Ticker': ticker,\n",
        "            'Total Windows': total_windows,\n",
        "            'Pump-and-Dump Flags': pump_dump_count\n",
        "        }])\n",
        "        results = pd.concat([results, new_row], ignore_index=True)\n",
        "        #print(f\"  - {ticker}: Total Windows={total_windows}, Flagged={pump_dump_count}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ANALYSIS SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Sort results by the number of flags in descending order\n",
        "    results = results.sort_values(by='Pump-and-Dump Flags', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Filter for stocks with at least one pump-and-dump flag\n",
        "    pump_dump_results = results[results['Pump-and-Dump Flags'] > 0]\n",
        "\n",
        "    if not pump_dump_results.empty:\n",
        "        print(pump_dump_results.to_string(index=False))\n",
        "    else:\n",
        "        print(\"No stocks were classified as a 'Pump-and-Dump' event based on the 2024 data and the current model.\")\n",
        "\n",
        "    print(f\"Length of pump-and-dump dataframe: {len(pump_dump_results)}\")\n",
        "    print(\"\\nAnalysis complete. The 'Pump-and-Dump Flags' column indicates the number of times a 180-day period for a stock was classified as a pump-and-dump event.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tenvvXmMwCB4",
        "outputId": "624fcd59-85fb-4127-88a6-4c6840884305"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from 'bist_2024_prices.csv'.\n",
            "Successfully loaded trained model from 'best_model_windowed.pth'.\n",
            "Using device: cuda\n",
            "\n",
            "Analyzing BIST stocks...\n",
            "  - Skipping DCTTR.IS: Not enough data for a single window (106 < 120).\n",
            "  - Skipping GUNDG.IS: Not enough data for a single window (90 < 120).\n",
            "  - Skipping LYDYE.IS: Not enough data for a single window (70 < 120).\n",
            "  - Skipping TCKRC.IS: Not enough data for a single window (91 < 120).\n",
            "  - Skipping DURKN.IS: Not enough data for a single window (74 < 120).\n",
            "  - Skipping INTEK.IS: Not enough data for a single window (109 < 120).\n",
            "  - Skipping CEMZY.IS: Not enough data for a single window (80 < 120).\n",
            "  - Skipping QNBFK.IS: Not enough data for a single window (26 < 120).\n",
            "  - Skipping BINBN.IS: Not enough data for a single window (58 < 120).\n",
            "  - Skipping SMRVA.IS: Not enough data for a single window (9 < 120).\n",
            "  - Skipping BAHKM.IS: Not enough data for a single window (97 < 120).\n",
            "  - Skipping CGCAM.IS: Not enough data for a single window (10 < 120).\n",
            "  - Skipping ISKUR.IS: Not enough data for a single window (19 < 120).\n",
            "  - Skipping OZATD.IS: Not enough data for a single window (82 < 120).\n",
            "  - Skipping AHSGY.IS: Not enough data for a single window (86 < 120).\n",
            "\n",
            "==================================================\n",
            "ANALYSIS SUMMARY\n",
            "==================================================\n",
            "  Ticker Total Windows Pump-and-Dump Flags\n",
            "CELHA.IS             9                   9\n",
            "MEGAP.IS             9                   9\n",
            "PEKGY.IS             9                   9\n",
            "BJKAS.IS             9                   9\n",
            "AKYHO.IS             9                   9\n",
            "CONSE.IS             9                   9\n",
            " KGYO.IS             9                   9\n",
            "OSMEN.IS             9                   9\n",
            "VRGYO.IS             9                   8\n",
            "DIRIT.IS             9                   8\n",
            "BAYRK.IS             9                   8\n",
            "POLTK.IS             9                   8\n",
            "DITAS.IS             9                   8\n",
            "SEYKM.IS             9                   7\n",
            "IHEVA.IS             9                   7\n",
            "ORCAY.IS             9                   7\n",
            "ATSYH.IS             9                   7\n",
            "CCOLA.IS             9                   7\n",
            "KTLEV.IS             9                   7\n",
            "ZEDUR.IS             9                   7\n",
            " USAK.IS             9                   7\n",
            "SKYMD.IS             9                   7\n",
            "PRKAB.IS             9                   7\n",
            "SEKFK.IS             9                   7\n",
            "MNDRS.IS             9                   7\n",
            "BSOKE.IS             9                   6\n",
            "AGROT.IS             9                   6\n",
            "AKENR.IS             9                   6\n",
            "IMASM.IS             9                   6\n",
            "RTALB.IS             9                   6\n",
            "SANFM.IS             9                   6\n",
            " AYES.IS             9                   6\n",
            " FLAP.IS             9                   6\n",
            "KATMR.IS             9                   6\n",
            "TEHOL.IS             9                   6\n",
            "MTRYO.IS             9                   6\n",
            "ISFIN.IS             9                   6\n",
            " HKTM.IS             9                   6\n",
            "MERIT.IS             9                   6\n",
            "HUNER.IS             9                   6\n",
            "AGESA.IS             9                   6\n",
            "SNKRN.IS             9                   6\n",
            "IDGYO.IS             9                   6\n",
            "BRKVY.IS             9                   6\n",
            "OYLUM.IS             9                   6\n",
            "DMSAS.IS             9                   6\n",
            "ONCSM.IS             9                   6\n",
            "VKING.IS             9                   6\n",
            "LRSHO.IS             9                   6\n",
            "TRHOL.IS             9                   6\n",
            "VERTU.IS             9                   6\n",
            "TBORG.IS             9                   6\n",
            "CRDFA.IS             9                   6\n",
            "LYDHO.IS             9                   5\n",
            "SAMAT.IS             9                   5\n",
            "SNICA.IS             9                   5\n",
            "YUNSA.IS             9                   5\n",
            "GESAN.IS             9                   5\n",
            " BRKO.IS             9                   5\n",
            "PKART.IS             9                   5\n",
            "YESIL.IS             9                   5\n",
            "IHLAS.IS             9                   5\n",
            "A1CAP.IS             9                   5\n",
            "TSPOR.IS             9                   5\n",
            "EUKYO.IS             9                   5\n",
            "KLGYO.IS             9                   5\n",
            "KONYA.IS             9                   5\n",
            " ERSU.IS             9                   5\n",
            "FONET.IS             9                   5\n",
            "KLMSN.IS             9                   5\n",
            "SODSN.IS             9                   5\n",
            " EDIP.IS             9                   5\n",
            "GRNYO.IS             9                   5\n",
            "KRVGD.IS             9                   5\n",
            "BTCIM.IS             9                   5\n",
            "TOASO.IS             9                   5\n",
            "KLNMA.IS             9                   5\n",
            "AVTUR.IS             9                   5\n",
            "YONGA.IS             9                   5\n",
            "EUHOL.IS             9                   5\n",
            "EDATA.IS             9                   5\n",
            "RODRG.IS             9                   5\n",
            "KERVN.IS             9                   4\n",
            "SUMAS.IS             9                   4\n",
            "CMENT.IS             9                   4\n",
            "TSGYO.IS             9                   4\n",
            "KSTUR.IS             9                   4\n",
            "SNPAM.IS             9                   4\n",
            "ELITE.IS             9                   4\n",
            "DERIM.IS             9                   4\n",
            "AEFES.IS             9                   4\n",
            "LUKSK.IS             9                   4\n",
            " EUYO.IS             9                   4\n",
            "IZFAS.IS             9                   4\n",
            "JANTS.IS             9                   4\n",
            "DENGE.IS             9                   4\n",
            "MAKIM.IS             9                   4\n",
            "MEKAG.IS             9                   4\n",
            "MARBL.IS             9                   4\n",
            "YAYLA.IS             9                   4\n",
            "IZINV.IS             9                   4\n",
            "PSDTC.IS             9                   4\n",
            "AYGAZ.IS             9                   4\n",
            "PNSUT.IS             9                   4\n",
            "BLCYT.IS             9                   4\n",
            "GOKNR.IS             9                   4\n",
            "ISSEN.IS             9                   4\n",
            "ANHYT.IS             9                   4\n",
            "EYGYO.IS             9                   4\n",
            "AYCES.IS             9                   4\n",
            "METRO.IS             9                   4\n",
            "TRILC.IS             9                   4\n",
            "BEYAZ.IS             9                   4\n",
            "IHYAY.IS             9                   4\n",
            "ALGYO.IS             9                   4\n",
            "SURGY.IS             9                   4\n",
            "VAKKO.IS             9                   4\n",
            "OZRDN.IS             9                   4\n",
            "KIMMR.IS             9                   4\n",
            "IEYHO.IS             9                   4\n",
            "HEKTS.IS             9                   4\n",
            "SMART.IS             9                   4\n",
            "KAREL.IS             9                   4\n",
            "RAYSG.IS             9                   3\n",
            "KRGYO.IS             9                   3\n",
            "DARDL.IS             9                   3\n",
            " YGYO.IS             9                   3\n",
            "GSRAY.IS             9                   3\n",
            "GRTHO.IS             9                   3\n",
            "SRVGY.IS             9                   3\n",
            "BRYAT.IS             9                   3\n",
            "MOBTL.IS             9                   3\n",
            "ALARK.IS             9                   3\n",
            " ERCB.IS             9                   3\n",
            " DEVA.IS             9                   3\n",
            "CEOEM.IS             9                   3\n",
            " EKIZ.IS             9                   3\n",
            "MIATK.IS             9                   3\n",
            "IHLGM.IS             9                   3\n",
            "BURCE.IS             9                   3\n",
            "INGRM.IS             9                   3\n",
            "CATES.IS             9                   3\n",
            "DERHL.IS             9                   3\n",
            "PATEK.IS             7                   3\n",
            "DGNMO.IS             9                   3\n",
            "IHAAS.IS             9                   3\n",
            " ORMA.IS             9                   3\n",
            "KUTPO.IS             9                   3\n",
            "TDGYO.IS             9                   3\n",
            " MAVI.IS             9                   3\n",
            "BRISA.IS             9                   3\n",
            "ASUZU.IS             9                   3\n",
            "MAKTK.IS             9                   3\n",
            " BERA.IS             9                   3\n",
            "PNLSN.IS             9                   3\n",
            "ALVES.IS             6                   3\n",
            "GOLTS.IS             9                   3\n",
            "AKMGY.IS             9                   3\n",
            "MTRKS.IS             9                   3\n",
            "FENER.IS             9                   3\n",
            "KRSTL.IS             9                   3\n",
            "PSGYO.IS             9                   3\n",
            "HEDEF.IS             9                   3\n",
            "EGPRO.IS             9                   3\n",
            "ARENA.IS             9                   3\n",
            "ANELE.IS             9                   3\n",
            "KARTN.IS             9                   3\n",
            "EMNIS.IS             9                   3\n",
            "KOPOL.IS             9                   3\n",
            "VERUS.IS             9                   3\n",
            "DYOBY.IS             9                   2\n",
            "GARFA.IS             9                   2\n",
            "AVHOL.IS             9                   2\n",
            "ERBOS.IS             9                   2\n",
            "ETYAT.IS             9                   2\n",
            "TLMAN.IS             9                   2\n",
            "AKFYE.IS             9                   2\n",
            "PAMEL.IS             9                   2\n",
            "QUAGR.IS             9                   2\n",
            "DOBUR.IS             9                   2\n",
            "DGATE.IS             9                   2\n",
            "YIGIT.IS             2                   2\n",
            "GARAN.IS             9                   2\n",
            "KLRHO.IS             9                   2\n",
            "BEGYO.IS             9                   2\n",
            "MNDTR.IS             9                   2\n",
            "HDFGS.IS             9                   2\n",
            "EUREN.IS             9                   2\n",
            "INDES.IS             9                   2\n",
            "NIBAS.IS             9                   2\n",
            "ARZUM.IS             9                   2\n",
            "MOGAN.IS             6                   2\n",
            "TTRAK.IS             9                   2\n",
            "DURDO.IS             9                   2\n",
            "HURGZ.IS             9                   2\n",
            "PENGD.IS             9                   2\n",
            "TUCLK.IS             9                   2\n",
            "HATSN.IS             9                   2\n",
            "MARTI.IS             9                   2\n",
            "TATGD.IS             9                   2\n",
            "KBORU.IS             9                   2\n",
            "BURVA.IS             9                   2\n",
            "INVES.IS             6                   2\n",
            "PENTA.IS             9                   2\n",
            "AGHOL.IS             9                   2\n",
            "KORDS.IS             9                   2\n",
            "ANSGR.IS             9                   2\n",
            "ODINE.IS             5                   2\n",
            " DESA.IS             9                   2\n",
            "LIDFA.IS             9                   2\n",
            " OTTO.IS             9                   2\n",
            "NATEN.IS             9                   2\n",
            "RALYH.IS             9                   2\n",
            "KLSER.IS             9                   2\n",
            "POLHO.IS             9                   2\n",
            "TTKOM.IS             9                   2\n",
            "ESCOM.IS             9                   2\n",
            "PKENT.IS             9                   2\n",
            "MPARK.IS             9                   2\n",
            "GEDZA.IS             9                   2\n",
            "DESPC.IS             9                   2\n",
            "BRKSN.IS             9                   2\n",
            "GEREL.IS             9                   2\n",
            "DOKTA.IS             9                   2\n",
            "TURSG.IS             9                   2\n",
            " KENT.IS             9                   2\n",
            "KCHOL.IS             9                   2\n",
            "PRKME.IS             9                   2\n",
            " DOAS.IS             9                   2\n",
            " ALKA.IS             9                   2\n",
            "PARSN.IS             9                   2\n",
            "KOZAL.IS             9                   2\n",
            "NETAS.IS             9                   2\n",
            " TERA.IS             9                   2\n",
            "FORMT.IS             9                   2\n",
            "RUBNS.IS             9                   2\n",
            "CVKMD.IS             9                   2\n",
            "MMCAS.IS             9                   2\n",
            "MRGYO.IS             9                   2\n",
            "CRFSA.IS             9                   2\n",
            " UFUK.IS             9                   2\n",
            "VKGYO.IS             9                   2\n",
            "AZTEK.IS             9                   2\n",
            "TAVHL.IS             9                   2\n",
            "KAPLM.IS             9                   2\n",
            "CUSAN.IS             9                   2\n",
            "PLTUR.IS             9                   2\n",
            "GOODY.IS             9                   2\n",
            "KRDMA.IS             9                   2\n",
            "COSMO.IS             9                   2\n",
            "AKGRT.IS             9                   2\n",
            "QNBTR.IS             9                   2\n",
            "REEDR.IS             9                   2\n",
            "KFEIN.IS             9                   2\n",
            "VAKBN.IS             9                   2\n",
            "TCELL.IS             9                   1\n",
            "ONRYT.IS             2                   1\n",
            "IHGZT.IS             9                   1\n",
            "GLBMD.IS             9                   1\n",
            " ADEL.IS             9                   1\n",
            "ATEKS.IS             9                   1\n",
            "MERCN.IS             9                   1\n",
            "INTEM.IS             9                   1\n",
            "EGGUB.IS             9                   1\n",
            "CEMAS.IS             9                   1\n",
            " SOKE.IS             9                   1\n",
            "RNPOL.IS             9                   1\n",
            "BMSCH.IS             9                   1\n",
            "BNTAS.IS             9                   1\n",
            "BORSK.IS             7                   1\n",
            "TKNSA.IS             9                   1\n",
            "KRONT.IS             9                   1\n",
            "OYAYO.IS             9                   1\n",
            "CANTE.IS             9                   1\n",
            "BALAT.IS             9                   1\n",
            "KAYSE.IS             9                   1\n",
            "BRMEN.IS             9                   1\n",
            "ARASE.IS             9                   1\n",
            "BOBET.IS             9                   1\n",
            "BYDNR.IS             9                   1\n",
            "ZOREN.IS             9                   1\n",
            "MAGEN.IS             9                   1\n",
            "AKSUE.IS             9                   1\n",
            "VANGD.IS             9                   1\n",
            "EUPWR.IS             9                   1\n",
            "DZGYO.IS             9                   1\n",
            "MEPET.IS             9                   1\n",
            "METUR.IS             9                   1\n",
            "AVGYO.IS             9                   1\n",
            "DAPGM.IS             9                   1\n",
            "ATAGY.IS             9                   1\n",
            "OBASE.IS             9                   1\n",
            "GSDDE.IS             9                   1\n",
            "GENIL.IS             9                   1\n",
            "RGYAS.IS             4                   1\n",
            "SKTAS.IS             9                   1\n",
            "SONME.IS             9                   1\n",
            "ARDYZ.IS             9                   1\n",
            "VESTL.IS             9                   1\n",
            "KRTEK.IS             9                   1\n",
            "ANGEN.IS             9                   1\n",
            "ALFAS.IS             9                   1\n",
            "SUNTK.IS             9                   1\n",
            "MANAS.IS             9                   1\n",
            "IPEKE.IS             9                   1\n",
            "BIZIM.IS             9                   1\n",
            "BRSAN.IS             9                   1\n",
            "AYDEM.IS             9                   1\n",
            "SEKUR.IS             9                   1\n",
            "MHRGY.IS             9                   1\n",
            "FROTO.IS             9                   1\n",
            "BOSSA.IS             9                   1\n",
            "YYAPI.IS             9                   1\n",
            "GZNMI.IS             9                   1\n",
            "DNISI.IS             9                   1\n",
            "ALCAR.IS             9                   1\n",
            "ETILR.IS             9                   1\n",
            " EKOS.IS             9                   1\n",
            "PETUN.IS             9                   1\n",
            "VBTYZ.IS             9                   1\n",
            " LINK.IS             9                   1\n",
            "FORTE.IS             9                   1\n",
            "ENSRI.IS             9                   1\n",
            "BAKAB.IS             9                   1\n",
            "BANVT.IS             9                   1\n",
            "SARKY.IS             9                   1\n",
            "YKSLN.IS             9                   1\n",
            "ARSAN.IS             9                   1\n",
            "GIPTA.IS             9                   1\n",
            "PAPIL.IS             9                   1\n",
            "ALTNY.IS             3                   1\n",
            "TMPOL.IS             9                   1\n",
            "SAYAS.IS             9                   1\n",
            "TGSAS.IS             9                   1\n",
            "TRCAS.IS             9                   1\n",
            "KOZAA.IS             9                   1\n",
            " TMSN.IS             9                   1\n",
            "LKMNH.IS             9                   1\n",
            "TURGG.IS             9                   1\n",
            "TUREX.IS             9                   1\n",
            "EBEBK.IS             9                   1\n",
            "LMKDC.IS             7                   1\n",
            "ATATP.IS             9                   1\n",
            "OSTIM.IS             9                   1\n",
            "KONTR.IS             9                   1\n",
            "Length of pump-and-dump dataframe: 345\n",
            "\n",
            "Analysis complete. The 'Pump-and-Dump Flags' column indicates the number of times a 180-day period for a stock was classified as a pump-and-dump event.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}